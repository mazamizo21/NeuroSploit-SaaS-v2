# Deep Dive: PentAGI & PentestGPT — Full Architecture Analysis

## Date: 2026-02-12
## Purpose: Extract ALL learnings applicable to TazoSploit exploitation improvements

---

## 1. PentAGI Architecture (Go, 1k+ stars, vxcontrol)

### 1.1 Multi-Agent Team (THE KEY DIFFERENTIATOR)

PentAGI doesn't use a single agent. It uses a **team of 7+ specialized agents**, each with their own system prompt, tool access, and expertise:

| Agent | Role | Tools | Barrier Tool |
|-------|------|-------|-------------|
| **pentester** | Main attacker — runs commands, exploits vulns | terminal, file, browser, advice, coder, search, memorist, installer, guides, graphiti | `hack_result` |
| **coder** | Writes custom exploits, scripts, payloads | advice, installer, memorist, search, code_store, graphiti | `code_result` |
| **searcher** | OSINT, vuln research, exploit DB searches | google, duckduckgo, tavily, traversaal, perplexity, searxng, browser, memorist | `search_result` |
| **adviser** | Strategic guidance when stuck | (no tools — pure reasoning) | (none — returns text) |
| **memorist** | Recalls previous actions/successes from memory | terminal, file, search_in_memory, graphiti | `memorist_result` |
| **installer** | Sets up tools, installs deps | terminal, file, browser, advice, memorist, search, guides | `maintenance_result` |
| **reflector** | Catches when agent outputs text instead of tool calls | (meta-agent — redirects) | (none) |

**Key insight for TazoSploit:** When the pentester agent encounters something it can't exploit with standard tools, it DELEGATES to the `coder` agent to write a custom exploit. When it doesn't know what to try, it asks the `adviser`. When it needs to recall what worked before, it asks the `memorist`.

### 1.2 Barrier Tools Pattern

Every agent has a **barrier tool** — a special function it MUST call to "complete" its work. The pentester MUST call `hack_result` with a structured report. The coder MUST call `code_result` with the code. This prevents agents from just outputting text and claiming "done."

```go
// From tools.go — barrier tools stop the agent loop
barriers: map[string]struct{}{
    HackResultToolName: {},
},
```

The `HackResult` struct forces structured output:
```go
type HackResult struct {
    Result  string `json:"result" jsonschema:"required" jsonschema_description:"Fully detailed report"`
    Message string `json:"message" jsonschema:"required" jsonschema_description:"Short summary"`
}
```

**Applicable to TazoSploit:** Our agent can "complete" without proving exploitation. We should add a barrier-like requirement where findings must include structured exploitation evidence.

### 1.3 Repeating Command Detector

PentAGI has a `repeatingDetector` that catches when the agent runs the same command 3+ times:

```go
const RepeatingToolCallThreshold = 3

func (rd *repeatingDetector) detect(toolCall llms.ToolCall) bool {
    // Strips the "message" field (which varies) and compares name+args
    // If same command 3x in a row → returns true
}
```

When detected, PentAGI triggers the **reflector** which forces the agent to change strategy.

**Applicable to TazoSploit:** We have rudimentary repeat detection but it's not tied to strategy changes. PentAGI's approach of using a reflector agent to redirect is more sophisticated.

### 1.4 Knowledge Graph (Graphiti + Neo4j)

This is huge. PentAGI stores ALL execution history in a temporal knowledge graph:
- Every command and its output
- Every agent's reasoning
- Entity relationships (IP → Service → Vulnerability → Exploit)
- 7 search types: temporal_window, entity_relationships, diverse_results, episode_context, successful_tools, recent_context, entity_by_label

The pentester prompt says: **"ALWAYS search Graphiti BEFORE attempting any significant action"**

Search examples from the prompt:
- `"recent nmap scan results for 192.168.1.100"` (recent_context)
- `"successful sqlmap commands against MySQL"` (successful_tools)
- `"pentester agent analysis of SSH vulnerability"` (episode_context)
- `"different approaches to privilege escalation on Linux"` (diverse_results)

**Applicable to TazoSploit:** Our memory system is flat (JSON files). A graph-based approach where the agent can query "what exploitation techniques worked on similar services" would dramatically improve exploitation success rates.

### 1.5 Conversation Summarization (Chain AST)

PentAGI has a sophisticated conversation summarization system:
- Parses the conversation into an AST (Abstract Syntax Tree) with sections
- Summarizes old sections to keep context window manageable
- Preserves the last section (most recent actions) in full detail
- Has configurable thresholds: `lastSecBytes: 16KB`, `maxBPBytes: 8KB`, `maxQABytes: 20KB`

**Applicable to TazoSploit:** Our Spec 008 context summarization is similar but less structured. PentAGI's AST-based approach ensures nothing critical is lost during summarization.

### 1.6 Guide Storage/Retrieval

Agents can store successful methodologies as "guides" in a vector database:
```go
type StoreGuideAction struct {
    Guide    string // The methodology in markdown
    Question string // What problem this solves
    Type     string // install|configure|use|pentest|development|other
}
```

And later retrieve them when facing similar situations. This means successful exploitation techniques persist across runs.

**Applicable to TazoSploit:** We don't persist successful techniques between runs. Adding a guide store would let the agent learn from previous engagements.

### 1.7 Tool Schema — Terminal Action

PentAGI's terminal tool is more structured than ours:
```go
type TerminalAction struct {
    Input   string // Command to run
    Cwd     string // Working directory (REQUIRED — not persistent)
    Detach  Bool   // Background execution
    Timeout Int64  // Seconds (min 10, max 1200, default 60)
    Message string // Explanation for the user
}
```

Every tool call requires a `Message` field explaining WHY the agent is running that command. This creates an audit trail and forces the agent to articulate its strategy.

### 1.8 Docker Container Management

PentAGI spawns a fresh Docker container per "flow" (engagement):
- Uses `vxcontrol/kali-linux` image
- Adds `NET_RAW` capability (and optionally `NET_ADMIN`)
- Container has port bindings for reverse shells
- Container is cleaned up when the flow ends

The pentester prompt includes the container's ports: `"This container has the following ports which bind to the host: 0.0.0.0:PORT -> PORT/tcp"` — so the agent knows which ports to use for reverse shells.

**Applicable to TazoSploit:** We do this similarly, but we don't tell the agent which ports are available for listeners. This could be why our agent never sets up reverse shells.

---

## 2. PentestGPT Architecture (Python, USENIX Security 2024)

### 2.1 Claude Code SDK Integration

PentestGPT v1.0 wraps Claude Code as a subprocess:
```python
from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions

options = ClaudeAgentOptions(
    cwd=str(config.working_directory),
    permission_mode=config.permission_mode,
    system_prompt=self._build_system_prompt(),
    model=config.model,
)
client = ClaudeSDKClient(options=options)
await client.connect()
await client.query(task)
```

This means Claude Code handles ALL tool execution (bash, file editing, etc.) internally. PentestGPT just provides the system prompt and monitors the output stream.

**Key insight:** PentestGPT is architecturally simpler than PentAGI — it's a single agent with a very aggressive prompt. The prompt does ALL the heavy lifting.

### 2.2 The System Prompt (THE REAL SECRET)

PentestGPT's system prompt is ~4000 chars and covers:

#### a. "NEVER GIVE UP" Directive
```
CRITICAL REQUIREMENT - NEVER GIVE UP:
Your task is INCOMPLETE until you have captured at least one flag.
- If one technique doesn't work, try alternatives immediately
- If stuck for more than a few attempts, try completely different attack vectors
NEVER say "given the time spent" or "given the complexity" as a reason to stop.
```

#### b. "Finding is NOT Completion" Pattern
```
Remember:
- "I achieved arbitrary file write" is NOT completion - use it to get the flags
- "I have RCE" is NOT completion - use it to read user.txt and root.txt
- Partial success is NOT success - get ALL flags
```

#### c. 5 Detailed Fallback Strategies

**Reverse Shell Not Working?**
- Try different shells: bash, sh, python, php, perl, nc, socat
- Try different encodings: URL encode, base64, hex
- Try different ports: 80, 443, 8080, 4444, 1234
- Try bind shell instead of reverse shell
- Try staged payloads

**Privilege Escalation Stuck?**
- SUID binaries: `find / -perm -4000 2>/dev/null`
- Sudo rights: `sudo -l`
- Capabilities: `getcap -r / 2>/dev/null`
- Cron jobs: `cat /etc/crontab, ls -la /etc/cron.*`
- Writable /etc/ files: `find /etc -writable 2>/dev/null`
- Kernel exploits: `searchsploit kernel version`
- Running processes and services
- Database credentials, API keys in configs

**Web Exploitation Not Working?**
- Try manual exploitation if automated tools fail
- Different encodings, case variations, null bytes
- Polyglot payloads
- Chain multiple small vulnerabilities
- Check JavaScript source for API endpoints
- Try older/deprecated API versions

#### d. Self-Check Before Completion
```
BEFORE COMPLETING YOUR TASK:
1. Have I captured all required flags?
2. Did I actually READ the flag files and output their contents?
3. Am I providing a complete solution or just a partial one?
If NO → DO NOT conclude. Continue working.
```

### 2.3 Flag Detection (Regex Patterns)

PentestGPT has real-time flag detection in the output stream:
```python
FLAG_PATTERNS = [
    r"flag\{[^\}]+\}",           # flag{...}
    r"FLAG\{[^\}]+\}",           # FLAG{...}
    r"HTB\{[^\}]+\}",            # HTB{...}
    r"\b[a-f0-9]{32}\b",         # 32-char hex
    r"[A-Za-z0-9_]+\{[^\}]+\}",  # Generic CTF format
]
```

**Applicable to TazoSploit:** We could detect "proof of exploitation" patterns in real-time — data dumps, credential outputs, shell banners, etc.

### 2.4 Session Persistence

PentestGPT supports pausing and resuming sessions:
```python
class SessionStore:
    # File-based persistence in ~/.pentestgpt/sessions/
    # Supports session resumption with full context
```

The `AgentController` has a 5-state lifecycle: IDLE → RUNNING → PAUSED → COMPLETED → ERROR

### 2.5 Legacy PTT (Penetration Testing Tree)

The original PentestGPT (pre-Claude Code) used a structured task tree:
```
1. Reconnaissance - [to-do]
   1.1 Passive Information Gathering - (completed)
   1.2 Active Information Gathering - (completed)
   1.3 Identify Open Ports and Services - (to-do)
       1.3.1 Perform a full port scan - (to-do)
       1.3.2 Determine the purpose of each open port - (to-do)
```

This gave the agent a structured view of progress. The current version relies on Claude Code's internal reasoning instead.

**Applicable to TazoSploit:** A structured task tree could help our agent maintain focus. PentAGI does this via subtasks; PentestGPT did it via PTT. We should consider adding a similar structure.

---

## 3. Key Differences Between PentAGI vs PentestGPT vs TazoSploit

| Feature | PentAGI | PentestGPT | TazoSploit |
|---------|---------|------------|------------|
| Architecture | Multi-agent team (7+ agents) | Single agent (Claude Code) | Single agent (custom LLM loop) |
| Exploitation | Delegates to coder for custom exploits | Aggressive prompt only | Prompt + proof gate + auto-tracker |
| Memory | Knowledge graph (Graphiti/Neo4j) | Session persistence | Flat JSON files + Redis |
| Repeat Detection | repeatingDetector → reflector | Claude Code internal | Partial (noop detection) |
| Summarization | Chain AST with configurable thresholds | Claude Code internal | Spec 008 digest |
| Completion Gate | Barrier tools (hack_result) | Flag detection (regex) | Auto-complete (idle threshold) |
| Strategy Change | Adviser agent + reflector | Fallback strategies in prompt | Supervisor + force_pivot |
| Guide Storage | Vector DB guides per engagement | None | None |
| Tool Schemas | Strongly typed (Go structs) | Claude Code native | Bash string commands |
| Exploit Writing | Dedicated coder agent | Claude Code does it inline | No dedicated capability |

---

## 4. Actionable Improvements for TazoSploit (Prioritized)

### P0 — Already Implemented (v5)
- [x] Exploitation-mandatory directive in system prompt
- [x] Real proof requirements (data dumps, shell output, file reads)
- [x] Fallback strategies when tools fail
- [x] Post-exploitation deepening nudge
- [x] Weak evidence rejection in proof gate

### P1 — High Impact, Medium Effort
1. **Container port awareness** — Tell the agent which ports are available for listeners/reverse shells (PentAGI does this)
2. **Structured completion gate** — Require the agent to call a `hack_result`-equivalent with structured findings before marking complete
3. **Exploit output pattern matching** — Real-time detection of exploitation evidence in stdout (like PentestGPT's flag detection)
4. **Self-check before completion** — Before auto-complete, inject "Did you actually exploit anything? If not, continue." (PentestGPT pattern)

### P2 — High Impact, High Effort
5. **Coder sub-agent** — When standard tools fail, spawn a sub-agent that writes custom exploit scripts (PentAGI's `coder` agent)
6. **Adviser sub-agent** — When stuck for N iterations, consult a strategic adviser agent for new approaches (PentAGI's `adviser`)
7. **Guide persistence** — Store successful exploitation techniques in a vector DB for retrieval in future runs
8. **Knowledge graph** — Replace flat JSON memory with a graph structure tracking entities and relationships

### P3 — Medium Impact, Medium Effort
9. **Repeating command detector + reflector** — Detect exact repeat commands and force strategy changes (PentAGI's `repeatingDetector`)
10. **Structured terminal tool** — Require working directory, timeout, and explanation with every command (PentAGI's `TerminalAction`)
11. **Penetration Testing Tree** — Maintain a structured task tree showing progress per phase (PentestGPT legacy)

---

## 5. Code Snippets Worth Adapting

### 5.1 Repeating Detector (from PentAGI)
```python
class RepeatingDetector:
    THRESHOLD = 3
    
    def __init__(self):
        self.history = []
    
    def detect(self, command: str) -> bool:
        # Strip variable parts (timestamps, random IDs)
        normalized = self._normalize(command)
        
        if not self.history or self.history[-1] != normalized:
            self.history = [normalized]
            return False
        
        self.history.append(normalized)
        return len(self.history) >= self.THRESHOLD
    
    def _normalize(self, cmd: str) -> str:
        # Remove echo messages, keep actual commands
        lines = [l for l in cmd.split('\n') if not l.strip().startswith('echo')]
        return '\n'.join(lines).strip()
```

### 5.2 Exploitation Evidence Detector (inspired by PentestGPT)
```python
EXPLOITATION_EVIDENCE_PATTERNS = [
    r'uid=\d+\(',                    # Shell access (id command)
    r'root:x:0:0:',                  # /etc/passwd read
    r'root:\$\d+\$',                 # /etc/shadow read
    r'\d+ rows? in set',             # MySQL data dump
    r'Changed database context to',  # MSSQL access
    r'\(\d+ rows? affected\)',       # MSSQL data extraction
    r'BEGIN RSA PRIVATE KEY',        # Private key extraction
    r'password["\s:=]+[^\s]{4,}',    # Password in config
    r'Authorization: Bearer',        # Token extraction
    r'session opened',               # Meterpreter/shell session
    r'Meterpreter session \d+',      # MSF session
    r'NT AUTHORITY\\SYSTEM',         # Windows SYSTEM shell
    r'Administrator',                # Windows admin access
]
```

### 5.3 Self-Check Injection (inspired by PentestGPT)
```python
def inject_self_check(conversation, iteration, findings_proven):
    if iteration % 25 == 0 and iteration > 0:
        check = """
SELF-CHECK — STOP AND EVALUATE:
1. How many vulnerabilities have I ACTUALLY EXPLOITED (not just found)?
2. Did I extract real data (DB dumps, file contents, credentials)?
3. Have I tried DIFFERENT techniques for each finding, or kept repeating the same approach?
4. Am I doing real exploitation, or just running more recon?

If I haven't exploited anything yet: CHANGE STRATEGY NOW.
If I found creds but haven't used them: USE THEM NOW.
If I found RCE but haven't dumped data: DUMP DATA NOW.
"""
        conversation.append({"role": "user", "content": check})
```

---

## 6. Files Referenced

### PentAGI (cloned to /tmp/pentest-research/pentagi/)
- `backend/pkg/templates/prompts/pentester.tmpl` — Main pentester system prompt
- `backend/pkg/templates/prompts/coder.tmpl` — Custom exploit writer prompt
- `backend/pkg/templates/prompts/adviser.tmpl` — Strategic advisor prompt
- `backend/pkg/templates/prompts/reflector.tmpl` — Output format enforcer
- `backend/pkg/templates/prompts/summarizer.tmpl` — Conversation summarizer
- `backend/pkg/templates/prompts/subtasks_generator.tmpl` — Task decomposition
- `backend/pkg/tools/registry.go` — Tool definitions + barrier tools
- `backend/pkg/tools/args.go` — Tool argument schemas (TerminalAction, HackResult, etc.)
- `backend/pkg/tools/tools.go` — Tool executor + pentester executor config
- `backend/pkg/tools/terminal.go` — Docker container command execution
- `backend/pkg/providers/performer.go` — Agent chain execution loop
- `backend/pkg/providers/helpers.go` — Repeating detector, chain restore, summarization

### PentestGPT (cloned to /tmp/pentest-research/PentestGPT/)
- `CLAUDE.md` — Project architecture overview
- `pentestgpt/prompts/pentesting.py` — CTF system prompt (4000 chars, very aggressive)
- `pentestgpt/core/agent.py` — Claude Code SDK wrapper + flag detection
- `pentestgpt/core/controller.py` — 5-state lifecycle controller
- `pentestgpt/core/session.py` — Session persistence
- `legacy/pentestgpt/prompts/prompt_class.py` — Original PTT-based prompts
