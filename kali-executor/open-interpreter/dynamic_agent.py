#!/usr/bin/env python3
"""
TazoSploit  v2 - Dynamic AI Agent
Fully AI-driven with NO hardcoded solutions.
The AI decides which tools to use, how to approach problems, and how to troubleshoot.
"""

import os
import sys
import json
import subprocess
import time
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict, field

LOG_DIR = os.getenv("LOG_DIR", "/pentest/logs")
# Create log directory if it doesn't exist and path is writable
try:
    os.makedirs(LOG_DIR, exist_ok=True)
except (OSError, PermissionError):
    # Fallback to temp directory if /pentest is not writable (e.g., on macOS)
    import tempfile
    LOG_DIR = os.path.join(tempfile.gettempdir(), "tazosploit_logs")
    os.makedirs(LOG_DIR, exist_ok=True)

sys.path.insert(0, os.path.dirname(__file__))
from llm_client import LLMClient
from comprehensive_report import ComprehensiveReport

# Import new modules
try:
    from cve_lookup import CVELookup
    CVE_LOOKUP_AVAILABLE = True
except ImportError:
    CVE_LOOKUP_AVAILABLE = False
    print("Warning: CVE lookup not available")

try:
    from llm_providers import create_provider, auto_detect_provider
    MULTI_MODEL_AVAILABLE = True
except ImportError:
    MULTI_MODEL_AVAILABLE = False
    print("Warning: Multi-model support not available")

try:
    from memory import MemoryStore, MEMORY_INSTRUCTION, create_memory_prompt_section
    MEMORY_AVAILABLE = True
except ImportError:
    MEMORY_AVAILABLE = False
    print("Warning: Memory system not available")


@dataclass
class Execution:
    """Captures any execution - command, script, or tool"""
    timestamp: str
    iteration: int
    execution_type: str  # command, python, bash, msfconsole, etc.
    content: str         # the actual command/code
    stdout: str
    stderr: str
    exit_code: int
    duration_ms: int
    success: bool
    tool_used: str       # detected tool name
    mitre_techniques: List[str] = field(default_factory=list)  # MITRE ATT&CK technique IDs
    

class DynamicAgent:
    """
    Fully dynamic AI agent that:
    - Has NO hardcoded exploit logic
    - Lets the AI decide which tools to use
    - Can execute ANY command/tool in Kali
    - Captures all I/O for debugging
    - Feeds errors back to AI for troubleshooting
    
    The AI is instructed via system prompt only - no hardcoded behavior.
    """
    
    # System prompt - this is the ONLY place we guide AI behavior
    SYSTEM_PROMPT_BASE = """You are an autonomous penetration testing AI with ROOT access to a Linux system.

**COMMAND FORMAT:**
```bash
command here
```
No comments inside the block.

**DECISION TREE - WHEN TO USE WHAT:**

1. **Command not found (exit 127)?**
   - FIRST: `websearch "kali linux <tool> package name"` to find correct package
   - THEN: `apt-get update && apt-get install -y <package>`
   - DO NOT guess package names - search first!

2. **Wrong syntax or tool error?**
   - FIRST: Try `<tool> --help` or `<tool> -h` (fast, local)
   - IF still unclear: `docslookup "<tool> syntax examples"`

3. **Need a resource (wordlist, script)?**
   - Use `download "<resource>"` ONCE - it remembers what you downloaded
   - DO NOT download the same file twice
   - Check if file exists first: `ls -la /tmp/<filename>`

4. **Need to research something?**
   - `websearch "<specific question>"` for vulnerabilities, exploits, techniques

**AVOID LOOPS:**
- If a command fails 2+ times with same error, try a DIFFERENT approach
- If you already downloaded a file, USE IT - don't download again
- Track what you've tried and don't repeat failed attempts

**TOOLS AVAILABLE:**
- `websearch "query"` - Search internet (use for package names, exploits, techniques)
- `docslookup "tool"` - Get tool documentation (use for syntax help)
- `download "resource"` - Download files (wordlists go to /tmp/)
- `<tool> --help` - Local help (try this FIRST for syntax)
- `apt-cache search <keyword>` - Search local packages
- `apt-get install -y <package>` - Install packages

**YOUR MISSION:**
Complete security assessment until you achieve full access.

**OUTPUT:**
Brief analysis, then one bash command block. Wait for result.

Be smart. Don't repeat yourself. Make progress.
"""

    def __init__(self, log_dir: str = LOG_DIR, mitre_context: str = None, 
                 llm_provider: str = None, websocket = None, session_id: str = None, max_iterations: int = 50):
        self.log_dir = log_dir
        self.session_id = session_id or f"session_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}"
        self.websocket = websocket
        
        # Initialize LLM (support multi-model)
        if llm_provider and MULTI_MODEL_AVAILABLE:
            if llm_provider == "auto":
                provider = auto_detect_provider()
            else:
                provider = create_provider(llm_provider)
            self.llm = provider
            self.llm_is_provider = True
        else:
            self.llm = LLMClient(log_dir)
            self.llm_is_provider = False
        
        # Initialize CVE lookup
        self.cve_lookup = CVELookup() if CVE_LOOKUP_AVAILABLE else None
        
        self.executions: List[Execution] = []
        self.conversation: List[Dict] = []
        self.iteration = 0
        self.max_iterations = max_iterations
        self.mitre_context = mitre_context
        self.comprehensive_report = ComprehensiveReport()
        self.target = None
        self.objective = None
        
        # State tracking to prevent loops and duplicates
        self.downloaded_files: set = set()  # Track downloaded resources
        self.failed_commands: Dict[str, int] = {}  # Track failed commands and count
        self.command_not_found: Dict[str, bool] = {}  # Track tools that need installation
        self.recent_commands: List[str] = []  # Last 5 commands for loop detection
        
        # Initialize persistent memory (will be set when target is known)
        self.memory_store = None
        
        # Build full system prompt with MITRE context if available
        system_prompt = self.SYSTEM_PROMPT_BASE
        
        # Add memory instruction
        if MEMORY_AVAILABLE:
            system_prompt += f"\n\n{MEMORY_INSTRUCTION}"
        
        if mitre_context:
            system_prompt += f"\n\n{mitre_context}"
        
        # Initialize with system prompt only
        self.conversation = [
            {"role": "system", "content": system_prompt}
        ]
        
        self._log("Dynamic Agent initialized - fully AI-driven with MITRE ATT&CK awareness")
    
    async def _send_websocket_update(self, event_type: str, data: Dict):
        """Send real-time update via WebSocket if available"""
        if self.websocket:
            try:
                await self.websocket.send_json({
                    "type": event_type,
                    "data": data,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "session_id": self.session_id
                })
            except Exception as e:
                print(f"WebSocket error: {e}")
    
    def _log(self, msg: str, level: str = "INFO"):
        timestamp = datetime.now(timezone.utc).isoformat()
        log_line = f"[{timestamp}] [{level}] {msg}"
        print(log_line)
        with open(f"{self.log_dir}/dynamic_agent.log", 'a') as f:
            f.write(log_line + '\n')
    
    def _extract_executable(self, response: str) -> List[Tuple[str, str]]:
        """
        Extract ALL executable blocks from response.
        Returns list of (type, content) tuples.
        Handles verbose LLM outputs that may include markdown inside code blocks.
        """
        import re
        executables = []
        
        # Find all fenced code blocks
        pattern = r'```(\w*)\s*\n(.*?)\n```'
        matches = re.findall(pattern, response, re.DOTALL)
        
        for block_type, content in matches:
            block_type = block_type.lower().strip()
            content = content.strip()
            
            if not content:
                continue
            
            # Skip if content is clearly markdown/explanation (not code)
            if content.startswith('**Execution Result') or content.startswith('- Tool:'):
                continue
            
            # For bash blocks, take the first line(s) that look like commands
            if block_type == 'bash' or not block_type:
                lines = content.split('\n')
                clean_lines = []
                
                for line in lines:
                    stripped = line.strip()
                    if not stripped:
                        continue
                    
                    # Stop if we hit markdown explanation after commands
                    if clean_lines and (stripped.startswith('*') or stripped.startswith('**')):
                        break
                    
                    # Skip pure markdown lines
                    if stripped.startswith('**') and stripped.endswith('**'):
                        continue
                    if stripped.startswith('- ') and ':' in stripped[:20]:
                        continue
                        
                    # This looks like a command or part of a command
                    clean_lines.append(line)
                
                content = '\n'.join(clean_lines).strip()
                if not content:
                    continue
                    
                block_type = 'bash'
            
            # Detect type if not specified
            if not block_type:
                if 'import ' in content[:100] or content.startswith('def '):
                    block_type = 'python'
                elif content.startswith('use ') or content.startswith('set '):
                    block_type = 'msfconsole'
                else:
                    block_type = 'bash'
            
            # Verify it looks like actual code
            first_char = content[0] if content else ''
            if first_char and first_char not in '*-':
                executables.append((block_type, content))
        
        return executables
    
    def _detect_tool(self, content: str) -> str:
        """Detect which tool is being used - no hardcoded list, just pattern matching"""
        first_word = content.split()[0] if content.split() else "unknown"
        # Remove path if present
        if '/' in first_word:
            first_word = first_word.split('/')[-1]
        return first_word
    
    def _execute(self, exec_type: str, content: str, timeout: int = 120) -> Execution:
        """
        Execute ANY type of content - command, script, msfconsole, etc.
        NO hardcoded handling per tool - generic execution.
        """
        self._log(f"Executing [{exec_type}]: {content[:100]}...")
        
        tool_used = self._detect_tool(content)
        start = time.time()
        
        try:
            # Determine working directory - use /pentest if it exists, otherwise current dir
            work_dir = "/pentest" if os.path.exists("/pentest") else os.getcwd()
            
            if exec_type == 'python':
                # Write to temp file and execute
                script_file = f"{self.log_dir}/temp_script.py"
                with open(script_file, 'w') as f:
                    f.write(content)
                result = subprocess.run(
                    ["python3", script_file],
                    capture_output=True, text=True, timeout=timeout, cwd=work_dir
                )
            elif exec_type == 'msfconsole':
                # Execute metasploit commands
                rc_file = f"{self.log_dir}/temp_msf.rc"
                with open(rc_file, 'w') as f:
                    f.write(content + "\nexit\n")
                result = subprocess.run(
                    ["msfconsole", "-q", "-r", rc_file],
                    capture_output=True, text=True, timeout=timeout, cwd=work_dir
                )
            else:
                # Default: execute as shell command
                result = subprocess.run(
                    content,
                    shell=True, capture_output=True, text=True, 
                    timeout=timeout, cwd=work_dir
                )
            
            duration = int((time.time() - start) * 1000)
            
            return Execution(
                timestamp=datetime.now(timezone.utc).isoformat(),
                iteration=self.iteration,
                execution_type=exec_type,
                content=content,
                stdout=result.stdout,
                stderr=result.stderr,
                exit_code=result.returncode,
                duration_ms=duration,
                success=result.returncode == 0,
                tool_used=tool_used
            )
            
        except subprocess.TimeoutExpired:
            return Execution(
                timestamp=datetime.now(timezone.utc).isoformat(),
                iteration=self.iteration,
                execution_type=exec_type,
                content=content,
                stdout="",
                stderr=f"TIMEOUT: Execution exceeded {timeout}s",
                exit_code=-1,
                duration_ms=timeout * 1000,
                success=False,
                tool_used=tool_used
            )
        except Exception as e:
            return Execution(
                timestamp=datetime.now(timezone.utc).isoformat(),
                iteration=self.iteration,
                execution_type=exec_type,
                content=content,
                stdout="",
                stderr=str(e),
                exit_code=-1,
                duration_ms=int((time.time() - start) * 1000),
                success=False,
                tool_used=tool_used
            )
    
    def _save_execution(self, execution: Execution):
        """Save execution to log"""
        self.executions.append(execution)
        with open(f"{self.log_dir}/agent_executions.jsonl", 'a') as f:
            f.write(json.dumps(asdict(execution)) + '\n')
    
    def _build_feedback(self, execution: Execution) -> str:
        """Build feedback message for LLM - includes state tracking hints"""
        output = execution.stdout[:3000] if execution.stdout else "(no stdout)"
        stderr = execution.stderr[:1500] if execution.stderr else "(no stderr)"
        
        feedback = f"""**Execution Result**
- Tool: `{execution.tool_used}`
- Exit Code: {execution.exit_code}
- Success: {execution.success}

**stdout:**
```
{output}
```

**stderr:**
```
{stderr}
```"""
        
        # Add smart hints based on state tracking
        hints = []
        
        # Track command not found (exit 127)
        if execution.exit_code == 127:
            tool = execution.tool_used
            self.command_not_found[tool] = True
            if tool not in self.failed_commands:
                self.failed_commands[tool] = 0
            self.failed_commands[tool] += 1
            
            if self.failed_commands[tool] == 1:
                hints.append(f"‚ö†Ô∏è `{tool}` not found. YOU MUST INSTALL IT.\nRun: `apt-cache search {tool}` then `apt-get install -y <package_name>`")
            elif self.failed_commands[tool] >= 2:
                hints.append(f"üõë `{tool}` failed {self.failed_commands[tool]} times. You MUST install it via apt-get or use a different tool.")
        
        # Track downloads
        if 'download' in execution.content.lower() and execution.success:
            # Extract resource name from download command
            import re
            match = re.search(r'download\s+["\']?([^"\']+)["\']?', execution.content)
            if match:
                resource = match.group(1)
                self.downloaded_files.add(resource)
                hints.append(f"‚úÖ Downloaded `{resource}` to /tmp/. Use it now - don't download again.")
        
        # Detect duplicate download attempts
        if 'download' in execution.content.lower():
            import re
            match = re.search(r'download\s+["\']?([^"\']+)["\']?', execution.content)
            if match and match.group(1) in self.downloaded_files:
                hints.append(f"‚ö†Ô∏è You already downloaded this file. Check /tmp/ and use it.")
        
        # Loop detection - same command repeated
        cmd_key = execution.content[:100]  # First 100 chars as key
        self.recent_commands.append(cmd_key)
        if len(self.recent_commands) > 5:
            self.recent_commands.pop(0)
        
        if self.recent_commands.count(cmd_key) >= 2:
            hints.append("üîÑ LOOP DETECTED: You're repeating commands. Try a DIFFERENT approach.")
        
        # Add hints to feedback
        if hints:
            feedback += "\n\n**IMPORTANT:**\n" + "\n".join(hints)
        
        feedback += "\n\nAnalyze and decide next action."
        return feedback
    
    def save_session(self) -> str:
        """Save current session state to file"""
        session_file = f"{self.log_dir}/session_{self.session_id}.json"
        
        session_data = {
            "session_id": self.session_id,
            "target": self.target,
            "objective": self.objective,
            "conversation": self.conversation,
            "executions": [asdict(e) for e in self.executions],
            "iteration": self.iteration,
            "max_iterations": self.max_iterations,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        with open(session_file, 'w') as f:
            json.dump(session_data, f, indent=2)
        
        self._log(f"Session saved: {session_file}")
        return session_file
    
    def load_session(self, session_id: str) -> bool:
        """Load session from file"""
        session_file = f"{self.log_dir}/session_{session_id}.json"
        
        try:
            with open(session_file, 'r') as f:
                session_data = json.load(f)
            
            self.session_id = session_data["session_id"]
            self.target = session_data.get("target")
            self.objective = session_data.get("objective")
            self.conversation = session_data["conversation"]
            self.iteration = session_data["iteration"]
            self.max_iterations = session_data.get("max_iterations", 50)
            
            # Restore executions
            self.executions = []
            for exec_dict in session_data["executions"]:
                self.executions.append(Execution(**exec_dict))
            
            self._log(f"Session loaded: {session_file}")
            return True
        except Exception as e:
            self._log(f"Failed to load session: {e}", "ERROR")
            return False
    
    def lookup_cve(self, cve_id: str) -> Optional[str]:
        """Lookup CVE information"""
        if not self.cve_lookup:
            return None
        
        cve_info = self.cve_lookup.lookup(cve_id)
        if cve_info:
            return self.cve_lookup.format_cve_info(cve_info)
        return None
    
    def _extract_memories(self, response: str):
        """
        Extract [REMEMBER: category] content from AI response and save to memory.
        AI decides what's worth remembering.
        """
        if not self.memory_store:
            return
        
        import re
        # Pattern: [REMEMBER: category] content (until end of line or next [REMEMBER)
        pattern = r'\[REMEMBER:\s*(\w+)\]\s*(.+?)(?=\[REMEMBER:|$)'
        matches = re.findall(pattern, response, re.IGNORECASE | re.DOTALL)
        
        for category, content in matches:
            category = category.lower().strip()
            content = content.strip()
            
            if content:
                memory = self.memory_store.add(
                    category=category,
                    content=content,
                    context={"target": self.target, "iteration": self.iteration},
                    importance="high" if category in ["credential_found", "vulnerability_found", "access_gained"] else "medium"
                )
                if memory:
                    self._log(f"Memory saved: [{category}] {content[:50]}...")
    
    def _auto_extract_learnings(self, execution: Execution):
        """
        Automatically extract learnings from execution results.
        Called after each execution to capture important info.
        """
        if not self.memory_store:
            return
        
        # Auto-save successful package installations
        if execution.success and 'apt-get install' in execution.content:
            import re
            match = re.search(r'apt-get install\s+(?:-y\s+)?(\S+)', execution.content)
            if match:
                package = match.group(1)
                self.memory_store.add(
                    category="tool_installed",
                    content=f"Installed package: {package}",
                    context={"target": self.target},
                    importance="medium"
                )
        
        # Auto-save when tool not found (exit 127) - so we remember to search
        if execution.exit_code == 127:
            tool = execution.tool_used
            self.memory_store.add(
                category="tool_failed",
                content=f"Tool '{tool}' not found - needs package installation",
                context={"target": self.target},
                importance="low"
            )
    
    def run(self, target: str, objective: str) -> Dict:
        """
        Run the agent with a target and objective.
        The AI decides everything else.
        """
        self.target = target
        self.objective = objective
        
        self._log(f"Starting engagement: {target}")
        self._log(f"Objective: {objective}")
        
        # Initialize persistent memory for this target
        if MEMORY_AVAILABLE:
            tenant_id = os.environ.get("TENANT_ID", "default")
            self.memory_store = MemoryStore(tenant_id=tenant_id, target=target)
            self._log(f"Memory store initialized: {len(self.memory_store.get_all())} memories loaded")
        
        # Initial prompt - just the objective, AI decides approach
        initial_prompt = f"""**TARGET**: {target}

**OBJECTIVE**: {objective}

"""
        
        # Add relevant memories from previous sessions
        if self.memory_store:
            memory_context = create_memory_prompt_section(
                self.memory_store, 
                context_keywords=[target.split(':')[0], 'credential', 'vulnerability', 'tool']
            )
            if memory_context:
                initial_prompt += f"\n{memory_context}\n\n"
        
        initial_prompt += """
**AVAILABLE TOOLS**:
- `websearch "query"`: Search the internet (Tavily/Bravo) for CVEs, exploits, or docs.
- `docslookup "tool"`: Get syntax and usage for security tools.
- `download "url"`: Download files to current directory.
- `apt-get install -y package`: Install any missing tools.

You are now autonomous. Begin your assessment. Decide your approach and execute."""
        
        self.conversation.append({"role": "user", "content": initial_prompt})
        
        while self.iteration < self.max_iterations:
            self.iteration += 1
            self._log(f"=== Iteration {self.iteration}/{self.max_iterations} ===")
            
            # Get AI response
            try:
                if self.llm_is_provider:
                    response, usage = self.llm.chat(self.conversation)
                else:
                    response = self.llm.chat(self.conversation)
                    usage = {}
                
                self.conversation.append({"role": "assistant", "content": response})
                self._log(f"AI response: {len(response)} chars")
                
                # Extract memories from AI response (AI decides what to remember)
                self._extract_memories(response)
                
                # Auto-save session every 5 iterations
                if self.iteration % 5 == 0:
                    self.save_session()
            except Exception as e:
                self._log(f"LLM error: {e}", "ERROR")
                break
            
            # Extract executable blocks
            executables = self._extract_executable(response)
            
            if not executables:
                # AI didn't provide commands - push for more action
                # NEVER stop early - always push for next steps
                done_indicators = ["complete", "finished", "concluded", "final report", "audit is complete"]
                if any(ind in response.lower() for ind in done_indicators):
                    # Check if we have REAL exploitation (not just credentials)
                    has_real_exploitation = self._check_exploitation_depth()
                    
                    if not has_real_exploitation:
                        # NO REAL EXPLOITATION - push harder
                        self.conversation.append({
                            "role": "user",
                            "content": """‚ùå NOT COMPLETE - You found credentials but did NOT exploit actual vulnerabilities.

REQUIRED EXPLOITATION (NOT JUST CREDENTIALS):

1. **SQL Injection** ‚Üí Use sqlmap with --dump to extract database contents
   Example: sqlmap -u "http://target/page?id=1" --batch --dump

2. **Command Injection** ‚Üí Execute system commands via vulnerable parameters
   Example: curl "http://target/api/exec?cmd=id;whoami;cat /etc/passwd"

3. **File Upload ‚Üí RCE** ‚Üí Upload webshell and execute commands
   Example: Upload shell.php, then access it to run commands

4. **Database Direct Access** ‚Üí Connect and dump ALL tables
   Example: mysql -h 10.0.4.40 -u root -proot123 -e "SHOW DATABASES; USE db; SELECT * FROM users;"

5. **XXE/SSRF** ‚Üí Read internal files or access internal services
   Example: Send XXE payload to read /etc/passwd

6. **LFI/Directory Traversal** ‚Üí Read sensitive files
   Example: curl "http://target/page?file=../../../../etc/passwd"

Provide the ACTUAL EXPLOITATION commands NOW (not just login attempts)."""
                        })
                        continue
                    
                    # AI says done - but we want ALL steps including lateral movement
                    if self.iteration < self.max_iterations - 5:
                        self.conversation.append({
                            "role": "user",
                            "content": """Good progress, but we need to continue deeper. Now:

1. **If you found credentials** ‚Üí Use them to access OTHER services (database, SSH, other hosts)
2. **If you found other hosts** ‚Üí Scan and test them with discovered credentials
3. **If you got access** ‚Üí Extract MORE data (database dumps, config files, /etc/shadow)
4. **Try alternatives** ‚Üí If one approach failed, try a different tool or technique

IMPORTANT: Create an account on /register if login failed, then use that to access protected areas.
Try default PostgreSQL credentials (postgres:postgres) on port 5432.
Try connecting to any discovered internal services.

Continue the assessment - provide the next commands."""
                        })
                        continue
                    else:
                        self._log("Max iterations approaching - accepting completion")
                        break
                
                # Ask AI to provide actionable commands
                self.conversation.append({
                    "role": "user",
                    "content": "Please provide specific commands in bash code blocks. If previous approaches failed, try alternatives."
                })
                continue
            
            # Execute each block and collect results
            all_feedback = []
            for exec_type, content in executables:
                execution = self._execute(exec_type, content)
                self._save_execution(execution)
                
                # Auto-extract learnings from execution
                self._auto_extract_learnings(execution)
                
                self._log(f"  {execution.tool_used}: exit={execution.exit_code}")
                all_feedback.append(self._build_feedback(execution))
            
            # Send all results back to AI
            combined_feedback = "\n\n---\n\n".join(all_feedback)
            self.conversation.append({"role": "user", "content": combined_feedback})
        
        # Generate comprehensive report
        self.comprehensive_report.parse_executions([asdict(e) for e in self.executions])
        return self._generate_report()
    
    def _check_exploitation_depth(self) -> bool:
        """Check if we have real exploitation results (not just credentials)"""
        exploitation_keywords = [
            'database dump', 'table:', 'select * from', 'show databases',
            'webshell uploaded', 'command executed', 'shell.php',
            'reverse shell', '/etc/passwd', '/etc/shadow',
            'root@', 'uid=0', 'privilege escalation',
            'sqlmap', '--dump', 'mysqldump', 'pg_dump'
        ]
        
        for exec in self.executions:
            output = f"{exec.content} {exec.stdout} {exec.stderr}".lower()
            if any(keyword in output for keyword in exploitation_keywords):
                return True
        return False
    
    def _generate_report(self) -> Dict:
        """Generate final report with exploitation results"""
        tools_used = list(set(e.tool_used for e in self.executions))
        successful = sum(1 for e in self.executions if e.success)
        
        # Generate comprehensive report files
        comprehensive_json = self.comprehensive_report.generate_json_report()
        comprehensive_md = self.comprehensive_report.generate_markdown_report()
        
        # Save markdown report
        report_file = f"{self.log_dir}/COMPREHENSIVE_REPORT_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w') as f:
            f.write(comprehensive_md)
        self._log(f"Comprehensive report saved: {report_file}")
        
        # Extract exploitation results from conversation
        exploitation_results = {
            "credentials": [],
            "shells": [],
            "backdoors": [],
            "databases": [],
            "files": []
        }
        
        # Parse conversation for results
        for msg in self.conversation:
            if msg.get("role") == "assistant":
                content = msg.get("content", "").lower()
                if "password" in content and ":" in content:
                    exploitation_results["credentials"].append("Credentials extracted")
                if "webshell" in content or "shell.php" in content:
                    exploitation_results["shells"].append("Webshell deployed")
                if "reverse shell" in content:
                    exploitation_results["shells"].append("Reverse shell available")
                if "backdoor" in content or "svc_" in content:
                    exploitation_results["backdoors"].append("Backdoor account created")
                if "dump" in content or "database" in content:
                    exploitation_results["databases"].append("Database accessed")
        
        report = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "iterations": self.iteration,
            "total_executions": len(self.executions),
            "successful_executions": successful,
            "failed_executions": len(self.executions) - successful,
            "tools_used": tools_used,
            "exploitation_results": exploitation_results,
            "comprehensive_findings": comprehensive_json,
            "comprehensive_report_file": report_file,
            "llm_stats": self.llm.get_stats(),
            "executions": [asdict(e) for e in self.executions]
        }
        
        report_file = f"{self.log_dir}/agent_report_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        self._log(f"Report: {report_file}")
        return report


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="TazoSploit Dynamic AI Agent")
    parser.add_argument("--target", help="Target (IP, URL, or range)")
    parser.add_argument("--objective", help="What to accomplish")
    parser.add_argument("--max-iterations", type=int, default=15, help="Max iterations")
    parser.add_argument("--llm-provider", choices=["auto", "openai", "anthropic", "ollama", "lmstudio"], 
                        help="LLM provider to use")
    parser.add_argument("--resume", help="Resume from session ID")
    parser.add_argument("--cve", help="Lookup CVE information")
    
    args = parser.parse_args()
    
    # CVE lookup mode
    if args.cve:
        if CVE_LOOKUP_AVAILABLE:
            lookup = CVELookup()
            cve_info = lookup.lookup(args.cve)
            if cve_info:
                print(lookup.format_cve_info(cve_info))
            else:
                print(f"CVE {args.cve} not found")
        else:
            print("CVE lookup not available")
        return
    
    agent = DynamicAgent(llm_provider=args.llm_provider)
    agent.max_iterations = args.max_iterations
    
    # Resume mode
    if args.resume:
        if agent.load_session(args.resume):
            print(f"Resumed session: {args.resume}")
            if agent.target and agent.objective:
                report = agent.run(agent.target, agent.objective)
            else:
                print("Error: Session missing target/objective")
                return
        else:
            print(f"Failed to resume session: {args.resume}")
            return
    else:
        if not args.target or not args.objective:
            parser.error("--target and --objective required (unless using --resume or --cve)")
        report = agent.run(args.target, args.objective)
    
    print("\n" + "=" * 60)
    print("ENGAGEMENT COMPLETE")
    print("=" * 60)
    print(f"Iterations: {report['iterations']}")
    print(f"Executions: {report['total_executions']} ({report['successful_executions']} success)")
    print(f"Tools used: {', '.join(report['tools_used'])}")
    print(f"LLM tokens: {report['llm_stats']['total_tokens']}")
    print("=" * 60)


if __name__ == "__main__":
    main()
